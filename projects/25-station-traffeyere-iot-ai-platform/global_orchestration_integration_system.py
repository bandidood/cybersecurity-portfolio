#!/usr/bin/env python3
"""
Projet 25 - Plateforme IoT AI Station Traffey√®re
Composant 8: Syst√®me d'Orchestration et d'Int√©gration Globale

Syst√®me d'orchestration central coordonnant l'ensemble des composants de la 
plateforme IoT industrielle incluant :
- Orchestration des services distribu√©s
- Int√©gration des API et microservices
- Gestionnaire de configuration centralis√©e  
- Load balancing et haute disponibilit√©
- Monitoring global de la plateforme
- Auto-scaling et gestion des ressources
- Service mesh et communication inter-services
- D√©ploiement automatis√© et CI/CD
- Health checks et recovery automatique

Auteur: Sp√©cialiste S√©curit√© IoT Industriel
Date: 2024
"""

import os
import json
import asyncio
import logging
import time
import threading
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple, Optional, Union, Callable
from dataclasses import dataclass, field, asdict
from enum import Enum, auto
from pathlib import Path
import uuid
import yaml
import hashlib
from collections import deque, defaultdict
import signal
import socket
import psutil
import platform

# Orchestration et containerisation
try:
    import docker
    import kubernetes
    from kubernetes import client, config
    KUBE_AVAILABLE = True
except ImportError:
    KUBE_AVAILABLE = False
    print("Kubernetes/Docker non disponibles - mode simulation activ√©")

# Service discovery et mesh
try:
    import consul
    import etcd3
    SERVICE_DISCOVERY_AVAILABLE = True
except ImportError:
    SERVICE_DISCOVERY_AVAILABLE = False
    print("Service discovery non disponible")

# Monitoring et m√©triques
try:
    import prometheus_client
    from prometheus_client import Counter, Histogram, Gauge
    import grafana_api
    MONITORING_AVAILABLE = True
except ImportError:
    MONITORING_AVAILABLE = False
    print("Monitoring Prometheus/Grafana non disponible")

# Communication et messaging
import aiohttp
import websockets
import paho.mqtt.client as mqtt
import redis
import requests
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# Bases de donn√©es
try:
    import pymongo
    import sqlalchemy
    import psycopg2
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False
    print("Bases de donn√©es non disponibles")

# Load balancing et proxy
try:
    import haproxy_stats
    import nginx
    PROXY_AVAILABLE = True
except ImportError:
    PROXY_AVAILABLE = False
    print("Load balancers non disponibles")

# Configuration avanc√©e
import configparser
import toml
from jinja2 import Template

# Utilitaires
import schedule
import cron_descriptor
import croniter
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# Configuration des logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ServiceState(Enum):
    """√âtats des services."""
    STARTING = "starting"
    RUNNING = "running"
    STOPPING = "stopping"
    STOPPED = "stopped"
    ERROR = "error"
    UNKNOWN = "unknown"

class ServiceType(Enum):
    """Types de services de la plateforme."""
    CORE_ENGINE = "core_engine"
    SIMULATION = "simulation"
    REALTIME_SYNC = "realtime_sync"
    PREDICTIVE_AI = "predictive_ai"
    VISUALIZATION_3D = "visualization_3d"
    OPTIMIZATION = "optimization"
    SECURITY = "security"
    VR_AR_TRAINING = "vr_ar_training"
    DATABASE = "database"
    MESSAGE_BROKER = "message_broker"
    API_GATEWAY = "api_gateway"
    LOAD_BALANCER = "load_balancer"
    MONITORING = "monitoring"

class HealthStatus(Enum):
    """√âtats de sant√© des services."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    CRITICAL = "critical"

@dataclass
class ServiceInstance:
    """Instance de service dans la plateforme."""
    service_id: str
    service_type: ServiceType
    name: str
    version: str
    host: str
    port: int
    state: ServiceState = ServiceState.STOPPED
    health_status: HealthStatus = HealthStatus.UNKNOWN
    last_health_check: Optional[datetime] = None
    start_time: Optional[datetime] = None
    restart_count: int = 0
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    network_io: Dict[str, float] = field(default_factory=dict)
    config: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    health_check_url: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DeploymentConfiguration:
    """Configuration de d√©ploiement d'un service."""
    service_type: ServiceType
    image: str
    replicas: int
    resource_requests: Dict[str, str]
    resource_limits: Dict[str, str]
    environment_variables: Dict[str, str] = field(default_factory=dict)
    config_maps: List[str] = field(default_factory=list)
    secrets: List[str] = field(default_factory=list)
    volumes: List[Dict[str, Any]] = field(default_factory=list)
    network_policies: List[str] = field(default_factory=list)
    auto_scaling: Dict[str, Any] = field(default_factory=dict)

@dataclass
class SystemMetrics:
    """M√©triques syst√®me globales."""
    timestamp: datetime
    total_services: int
    running_services: int
    healthy_services: int
    total_cpu_usage: float
    total_memory_usage: float
    network_throughput: Dict[str, float]
    error_rate: float
    response_time_avg: float
    active_connections: int
    queue_depths: Dict[str, int] = field(default_factory=dict)
    custom_metrics: Dict[str, float] = field(default_factory=dict)

class ConfigurationManager:
    """Gestionnaire de configuration centralis√©e."""
    
    def __init__(self, config_dir: str = "./config"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        
        self.configurations = {}
        self.templates = {}
        self.watchers = {}
        self.observers = []
        
        self._load_configurations()
        self._setup_file_watchers()
        
    def _load_configurations(self):
        """Charge toutes les configurations."""
        for config_file in self.config_dir.glob("*.yaml"):
            try:
                with open(config_file, 'r') as f:
                    config_data = yaml.safe_load(f)
                    service_name = config_file.stem
                    self.configurations[service_name] = config_data
                    logger.info(f"Configuration charg√©e: {service_name}")
            except Exception as e:
                logger.error(f"Erreur chargement config {config_file}: {e}")
        
        # Configuration par d√©faut
        if not self.configurations:
            self._create_default_configurations()
    
    def _create_default_configurations(self):
        """Cr√©e les configurations par d√©faut."""
        default_configs = {
            'global': {
                'platform': {
                    'name': 'Station Traffey√®re IoT AI Platform',
                    'version': '1.0.0',
                    'environment': 'production',
                    'debug': False
                },
                'networking': {
                    'base_port': 8000,
                    'service_mesh_enabled': True,
                    'tls_enabled': True
                },
                'scaling': {
                    'auto_scaling_enabled': True,
                    'min_replicas': 1,
                    'max_replicas': 10,
                    'target_cpu_percent': 70
                },
                'monitoring': {
                    'metrics_enabled': True,
                    'health_check_interval': 30,
                    'alerting_enabled': True
                }
            },
            'services': {
                'physical_simulation': {
                    'port': 8001,
                    'replicas': 2,
                    'resources': {
                        'cpu': '500m',
                        'memory': '1Gi'
                    }
                },
                'realtime_sync': {
                    'port': 8002,
                    'replicas': 3,
                    'resources': {
                        'cpu': '300m',
                        'memory': '512Mi'
                    }
                },
                'predictive_models': {
                    'port': 8003,
                    'replicas': 2,
                    'resources': {
                        'cpu': '1000m',
                        'memory': '2Gi'
                    }
                },
                'visualization_3d': {
                    'port': 8004,
                    'replicas': 1,
                    'resources': {
                        'cpu': '800m',
                        'memory': '1.5Gi'
                    }
                },
                'autonomous_optimization': {
                    'port': 8005,
                    'replicas': 1,
                    'resources': {
                        'cpu': '2000m',
                        'memory': '4Gi'
                    }
                },
                'security_framework': {
                    'port': 8006,
                    'replicas': 2,
                    'resources': {
                        'cpu': '600m',
                        'memory': '1Gi'
                    }
                },
                'vr_ar_training': {
                    'port': 8007,
                    'replicas': 1,
                    'resources': {
                        'cpu': '1500m',
                        'memory': '3Gi'
                    }
                }
            }
        }
        
        # Sauvegarde des configurations par d√©faut
        for config_name, config_data in default_configs.items():
            self.save_configuration(config_name, config_data)
    
    def _setup_file_watchers(self):
        """Configure la surveillance des fichiers de configuration."""
        class ConfigChangeHandler(FileSystemEventHandler):
            def __init__(self, config_manager):
                self.config_manager = config_manager
                
            def on_modified(self, event):
                if event.is_directory:
                    return
                if event.src_path.endswith('.yaml'):
                    self.config_manager._reload_config(event.src_path)
        
        handler = ConfigChangeHandler(self)
        observer = Observer()
        observer.schedule(handler, str(self.config_dir), recursive=True)
        observer.start()
        self.observers.append(observer)
        
    def _reload_config(self, file_path: str):
        """Recharge une configuration modifi√©e."""
        try:
            config_name = Path(file_path).stem
            with open(file_path, 'r') as f:
                config_data = yaml.safe_load(f)
                self.configurations[config_name] = config_data
                logger.info(f"Configuration recharg√©e: {config_name}")
                
                # Notification des changements
                if config_name in self.watchers:
                    for callback in self.watchers[config_name]:
                        try:
                            callback(config_data)
                        except Exception as e:
                            logger.error(f"Erreur callback config {config_name}: {e}")
                            
        except Exception as e:
            logger.error(f"Erreur rechargement config {file_path}: {e}")
    
    def get_configuration(self, service_name: str) -> Dict[str, Any]:
        """R√©cup√®re la configuration d'un service."""
        return self.configurations.get(service_name, {})
    
    def save_configuration(self, service_name: str, config_data: Dict[str, Any]):
        """Sauvegarde une configuration."""
        self.configurations[service_name] = config_data
        
        config_file = self.config_dir / f"{service_name}.yaml"
        try:
            with open(config_file, 'w') as f:
                yaml.dump(config_data, f, default_flow_style=False)
            logger.info(f"Configuration sauvegard√©e: {service_name}")
        except Exception as e:
            logger.error(f"Erreur sauvegarde config {service_name}: {e}")
    
    def register_watcher(self, service_name: str, callback: Callable):
        """Enregistre un callback pour les changements de configuration."""
        if service_name not in self.watchers:
            self.watchers[service_name] = []
        self.watchers[service_name].append(callback)
    
    def get_service_configuration(self, service_type: ServiceType) -> Dict[str, Any]:
        """Configuration sp√©cifique pour un type de service."""
        services_config = self.get_configuration('services')
        service_name = service_type.value.replace('_', '_')
        
        base_config = services_config.get(service_name, {})
        global_config = self.get_configuration('global')
        
        # Fusion des configurations
        merged_config = {**global_config, **base_config}
        return merged_config
    
    def cleanup(self):
        """Nettoie les ressources."""
        for observer in self.observers:
            observer.stop()
            observer.join()

class ServiceDiscovery:
    """Service de d√©couverte et registre des services."""
    
    def __init__(self, backend: str = 'local'):
        self.backend = backend
        self.services = {}  # Registre local
        self.health_callbacks = {}
        self.consul_client = None
        self.etcd_client = None
        
        if backend == 'consul' and SERVICE_DISCOVERY_AVAILABLE:
            try:
                self.consul_client = consul.Consul()
            except Exception as e:
                logger.error(f"Erreur connexion Consul: {e}")
                self.backend = 'local'
                
        elif backend == 'etcd' and SERVICE_DISCOVERY_AVAILABLE:
            try:
                self.etcd_client = etcd3.client()
            except Exception as e:
                logger.error(f"Erreur connexion etcd: {e}")
                self.backend = 'local'
    
    def register_service(self, service: ServiceInstance) -> bool:
        """Enregistre un service."""
        service_key = f"{service.service_type.value}:{service.service_id}"
        
        if self.backend == 'consul' and self.consul_client:
            try:
                self.consul_client.agent.service.register(
                    name=service.service_type.value,
                    service_id=service.service_id,
                    address=service.host,
                    port=service.port,
                    tags=[service.version, service.state.value],
                    check=consul.Check.http(
                        f"http://{service.host}:{service.port}/health",
                        interval="10s"
                    )
                )
                logger.info(f"Service enregistr√© dans Consul: {service_key}")
                
            except Exception as e:
                logger.error(f"Erreur enregistrement Consul {service_key}: {e}")
                return False
                
        elif self.backend == 'etcd' and self.etcd_client:
            try:
                service_data = {
                    'host': service.host,
                    'port': service.port,
                    'state': service.state.value,
                    'version': service.version,
                    'registered_at': datetime.now().isoformat()
                }
                
                self.etcd_client.put(
                    f"/services/{service.service_type.value}/{service.service_id}",
                    json.dumps(service_data)
                )
                logger.info(f"Service enregistr√© dans etcd: {service_key}")
                
            except Exception as e:
                logger.error(f"Erreur enregistrement etcd {service_key}: {e}")
                return False
        else:
            # Registre local
            self.services[service_key] = service
            logger.info(f"Service enregistr√© localement: {service_key}")
        
        return True
    
    def deregister_service(self, service_id: str, service_type: ServiceType) -> bool:
        """D√©senregistre un service."""
        service_key = f"{service_type.value}:{service_id}"
        
        if self.backend == 'consul' and self.consul_client:
            try:
                self.consul_client.agent.service.deregister(service_id)
                logger.info(f"Service d√©senregistr√© de Consul: {service_key}")
            except Exception as e:
                logger.error(f"Erreur d√©senregistrement Consul {service_key}: {e}")
                return False
                
        elif self.backend == 'etcd' and self.etcd_client:
            try:
                self.etcd_client.delete(f"/services/{service_type.value}/{service_id}")
                logger.info(f"Service d√©senregistr√© d'etcd: {service_key}")
            except Exception as e:
                logger.error(f"Erreur d√©senregistrement etcd {service_key}: {e}")
                return False
        else:
            # Registre local
            if service_key in self.services:
                del self.services[service_key]
                logger.info(f"Service d√©senregistr√© localement: {service_key}")
        
        return True
    
    def discover_services(self, service_type: ServiceType) -> List[ServiceInstance]:
        """D√©couvre les services d'un type donn√©."""
        services = []
        
        if self.backend == 'consul' and self.consul_client:
            try:
                _, service_list = self.consul_client.health.service(
                    service_type.value, passing=True
                )
                
                for service_info in service_list:
                    service = service_info['Service']
                    services.append(ServiceInstance(
                        service_id=service['ID'],
                        service_type=service_type,
                        name=service['Service'],
                        version=service.get('Tags', ['unknown'])[0],
                        host=service['Address'],
                        port=service['Port'],
                        state=ServiceState.RUNNING,
                        health_status=HealthStatus.HEALTHY
                    ))
                    
            except Exception as e:
                logger.error(f"Erreur d√©couverte Consul {service_type.value}: {e}")
                
        elif self.backend == 'etcd' and self.etcd_client:
            try:
                prefix = f"/services/{service_type.value}/"
                for value, metadata in self.etcd_client.get_prefix(prefix):
                    service_data = json.loads(value.decode())
                    service_id = metadata.key.decode().split('/')[-1]
                    
                    services.append(ServiceInstance(
                        service_id=service_id,
                        service_type=service_type,
                        name=service_type.value,
                        version=service_data.get('version', 'unknown'),
                        host=service_data['host'],
                        port=service_data['port'],
                        state=ServiceState(service_data['state']),
                        health_status=HealthStatus.UNKNOWN
                    ))
                    
            except Exception as e:
                logger.error(f"Erreur d√©couverte etcd {service_type.value}: {e}")
        else:
            # Registre local
            for service_key, service in self.services.items():
                if service.service_type == service_type:
                    services.append(service)
        
        return services
    
    def get_service_health(self, service_id: str) -> HealthStatus:
        """V√©rifie la sant√© d'un service."""
        # Impl√©mentation simplifi√©e
        if service_id in self.health_callbacks:
            try:
                return self.health_callbacks[service_id]()
            except Exception as e:
                logger.error(f"Erreur health check {service_id}: {e}")
                return HealthStatus.UNHEALTHY
        
        return HealthStatus.UNKNOWN

class LoadBalancer:
    """Load balancer pour distribuer la charge entre services."""
    
    def __init__(self, strategy: str = 'round_robin'):
        self.strategy = strategy
        self.service_pools = defaultdict(list)
        self.current_index = defaultdict(int)
        self.service_weights = defaultdict(lambda: 1)
        self.health_checks = {}
        
    def add_service_to_pool(self, service_type: ServiceType, 
                           service: ServiceInstance, weight: int = 1):
        """Ajoute un service au pool de load balancing."""
        pool_key = service_type.value
        self.service_pools[pool_key].append(service)
        self.service_weights[f"{pool_key}:{service.service_id}"] = weight
        logger.info(f"Service ajout√© au pool {pool_key}: {service.service_id}")
    
    def remove_service_from_pool(self, service_type: ServiceType, service_id: str):
        """Retire un service du pool."""
        pool_key = service_type.value
        self.service_pools[pool_key] = [
            s for s in self.service_pools[pool_key] 
            if s.service_id != service_id
        ]
        weight_key = f"{pool_key}:{service_id}"
        if weight_key in self.service_weights:
            del self.service_weights[weight_key]
        logger.info(f"Service retir√© du pool {pool_key}: {service_id}")
    
    def get_service(self, service_type: ServiceType) -> Optional[ServiceInstance]:
        """S√©lectionne un service selon la strat√©gie de load balancing."""
        pool_key = service_type.value
        
        if not self.service_pools[pool_key]:
            return None
        
        healthy_services = [
            s for s in self.service_pools[pool_key]
            if s.health_status == HealthStatus.HEALTHY
        ]
        
        if not healthy_services:
            # Fallback vers tous les services si aucun healthy
            healthy_services = self.service_pools[pool_key]
        
        if self.strategy == 'round_robin':
            return self._round_robin_selection(pool_key, healthy_services)
        elif self.strategy == 'least_connections':
            return self._least_connections_selection(healthy_services)
        elif self.strategy == 'weighted_round_robin':
            return self._weighted_round_robin_selection(pool_key, healthy_services)
        elif self.strategy == 'random':
            return self._random_selection(healthy_services)
        else:
            return healthy_services[0] if healthy_services else None
    
    def _round_robin_selection(self, pool_key: str, services: List[ServiceInstance]) -> ServiceInstance:
        """S√©lection round-robin."""
        if not services:
            return None
        
        index = self.current_index[pool_key] % len(services)
        self.current_index[pool_key] = (index + 1) % len(services)
        return services[index]
    
    def _least_connections_selection(self, services: List[ServiceInstance]) -> ServiceInstance:
        """S√©lection par le moins de connexions actives."""
        if not services:
            return None
        
        # Tri par nombre de connexions actives (simul√© par l'usage CPU)
        return min(services, key=lambda s: s.cpu_usage)
    
    def _weighted_round_robin_selection(self, pool_key: str, services: List[ServiceInstance]) -> ServiceInstance:
        """S√©lection weighted round-robin."""
        if not services:
            return None
        
        # Impl√©mentation simplifi√©e du weighted round-robin
        total_weight = sum(
            self.service_weights.get(f"{pool_key}:{s.service_id}", 1)
            for s in services
        )
        
        if total_weight == 0:
            return services[0]
        
        # S√©lection bas√©e sur le poids
        current_weight = self.current_index[pool_key] % total_weight
        cumulative_weight = 0
        
        for service in services:
            weight = self.service_weights.get(f"{pool_key}:{service.service_id}", 1)
            cumulative_weight += weight
            if current_weight < cumulative_weight:
                self.current_index[pool_key] = (self.current_index[pool_key] + 1) % total_weight
                return service
        
        return services[0]
    
    def _random_selection(self, services: List[ServiceInstance]) -> ServiceInstance:
        """S√©lection al√©atoire."""
        import random
        return random.choice(services) if services else None

class HealthChecker:
    """Syst√®me de v√©rification de sant√© des services."""
    
    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.is_running = False
        self.health_checks = {}
        self.service_registry = {}
        self.health_history = defaultdict(deque)
        
    def register_service_for_health_check(self, service: ServiceInstance):
        """Enregistre un service pour les health checks."""
        self.service_registry[service.service_id] = service
        logger.info(f"Service enregistr√© pour health check: {service.service_id}")
    
    async def start_health_monitoring(self):
        """D√©marre le monitoring de sant√©."""
        self.is_running = True
        logger.info("D√©marrage du monitoring de sant√© des services")
        
        while self.is_running:
            await self._perform_health_checks()
            await asyncio.sleep(self.check_interval)
    
    async def _perform_health_checks(self):
        """Effectue les v√©rifications de sant√©."""
        tasks = []
        
        for service_id, service in self.service_registry.items():
            task = asyncio.create_task(self._check_service_health(service))
            tasks.append(task)
        
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, result in enumerate(results):
                service_id = list(self.service_registry.keys())[i]
                if isinstance(result, Exception):
                    logger.error(f"Erreur health check {service_id}: {result}")
                    self._update_service_health(service_id, HealthStatus.UNHEALTHY)
                else:
                    self._update_service_health(service_id, result)
    
    async def _check_service_health(self, service: ServiceInstance) -> HealthStatus:
        """V√©rifie la sant√© d'un service individuel."""
        try:
            # Health check HTTP
            if service.health_check_url:
                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                    async with session.get(service.health_check_url) as response:
                        if response.status == 200:
                            return HealthStatus.HEALTHY
                        elif response.status < 500:
                            return HealthStatus.DEGRADED
                        else:
                            return HealthStatus.UNHEALTHY
            else:
                # Fallback: v√©rification TCP
                return await self._tcp_health_check(service.host, service.port)
                
        except asyncio.TimeoutError:
            logger.warning(f"Timeout health check {service.service_id}")
            return HealthStatus.DEGRADED
        except Exception as e:
            logger.error(f"Erreur health check {service.service_id}: {e}")
            return HealthStatus.UNHEALTHY
    
    async def _tcp_health_check(self, host: str, port: int) -> HealthStatus:
        """V√©rification de sant√© TCP basique."""
        try:
            _, writer = await asyncio.open_connection(host, port)
            writer.close()
            await writer.wait_closed()
            return HealthStatus.HEALTHY
        except Exception:
            return HealthStatus.UNHEALTHY
    
    def _update_service_health(self, service_id: str, health_status: HealthStatus):
        """Met √† jour l'√©tat de sant√© d'un service."""
        if service_id in self.service_registry:
            service = self.service_registry[service_id]
            previous_status = service.health_status
            service.health_status = health_status
            service.last_health_check = datetime.now()
            
            # Historique
            self.health_history[service_id].append({
                'timestamp': datetime.now(),
                'status': health_status.value
            })
            
            # Garder seulement les 100 derniers checks
            if len(self.health_history[service_id]) > 100:
                self.health_history[service_id].popleft()
            
            # Log des changements d'√©tat
            if previous_status != health_status:
                logger.info(f"Changement sant√© {service_id}: {previous_status.value} -> {health_status.value}")
    
    def get_service_health_history(self, service_id: str) -> List[Dict[str, Any]]:
        """Retourne l'historique de sant√© d'un service."""
        return list(self.health_history.get(service_id, []))
    
    def stop_health_monitoring(self):
        """Arr√™te le monitoring de sant√©."""
        self.is_running = False
        logger.info("Monitoring de sant√© arr√™t√©")

class MetricsCollector:
    """Collecteur de m√©triques syst√®me et applicatives."""
    
    def __init__(self):
        self.metrics_history = deque(maxlen=10000)
        self.service_metrics = defaultdict(deque)
        self.is_collecting = False
        
        # M√©triques Prometheus si disponible
        if MONITORING_AVAILABLE:
            self.http_requests = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
            self.response_time = Histogram('http_request_duration_seconds', 'HTTP request duration')
            self.active_connections = Gauge('active_connections', 'Number of active connections')
            self.service_health = Gauge('service_health', 'Service health status', ['service_id'])
    
    async def start_metrics_collection(self, interval: int = 60):
        """D√©marre la collecte de m√©triques."""
        self.is_collecting = True
        logger.info("D√©marrage de la collecte de m√©triques")
        
        while self.is_collecting:
            await self._collect_system_metrics()
            await asyncio.sleep(interval)
    
    async def _collect_system_metrics(self):
        """Collecte les m√©triques syst√®me."""
        try:
            # M√©triques syst√®me
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            network = psutil.net_io_counters()
            
            # M√©triques r√©seau
            network_metrics = {
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv,
                'packets_sent': network.packets_sent,
                'packets_recv': network.packets_recv
            }
            
            # Cr√©ation de la m√©trique globale
            system_metric = SystemMetrics(
                timestamp=datetime.now(),
                total_services=0,  # √Ä remplir par l'orchestrateur
                running_services=0,  # √Ä remplir par l'orchestrateur
                healthy_services=0,  # √Ä remplir par l'orchestrateur
                total_cpu_usage=cpu_percent,
                total_memory_usage=memory.percent,
                network_throughput=network_metrics,
                error_rate=0.0,  # √Ä calculer
                response_time_avg=0.0,  # √Ä calculer
                active_connections=0  # √Ä remplir
            )
            
            self.metrics_history.append(system_metric)
            
            # Mise √† jour des m√©triques Prometheus si disponible
            if MONITORING_AVAILABLE:
                self.active_connections.set(len(psutil.net_connections()))
            
        except Exception as e:
            logger.error(f"Erreur collecte m√©triques: {e}")
    
    def record_service_metric(self, service_id: str, metric_name: str, value: float):
        """Enregistre une m√©trique de service."""
        metric_entry = {
            'timestamp': datetime.now(),
            'metric_name': metric_name,
            'value': value
        }
        
        self.service_metrics[service_id].append(metric_entry)
        
        # Garder seulement les 1000 derni√®res m√©triques par service
        if len(self.service_metrics[service_id]) > 1000:
            self.service_metrics[service_id] = deque(
                list(self.service_metrics[service_id])[-1000:],
                maxlen=1000
            )
    
    def get_system_metrics_summary(self, time_window: timedelta = None) -> Dict[str, Any]:
        """Retourne un r√©sum√© des m√©triques syst√®me."""
        if time_window:
            cutoff_time = datetime.now() - time_window
            relevant_metrics = [
                m for m in self.metrics_history 
                if m.timestamp >= cutoff_time
            ]
        else:
            relevant_metrics = list(self.metrics_history)
        
        if not relevant_metrics:
            return {}
        
        # Calculs statistiques
        cpu_values = [m.total_cpu_usage for m in relevant_metrics]
        memory_values = [m.total_memory_usage for m in relevant_metrics]
        
        return {
            'time_range': {
                'start': relevant_metrics[0].timestamp.isoformat(),
                'end': relevant_metrics[-1].timestamp.isoformat(),
                'samples': len(relevant_metrics)
            },
            'cpu_usage': {
                'avg': sum(cpu_values) / len(cpu_values),
                'min': min(cpu_values),
                'max': max(cpu_values)
            },
            'memory_usage': {
                'avg': sum(memory_values) / len(memory_values),
                'min': min(memory_values),
                'max': max(memory_values)
            },
            'latest_metrics': asdict(relevant_metrics[-1]) if relevant_metrics else {}
        }
    
    def stop_metrics_collection(self):
        """Arr√™te la collecte de m√©triques."""
        self.is_collecting = False
        logger.info("Collecte de m√©triques arr√™t√©e")

class GlobalOrchestrator:
    """Orchestrateur principal de la plateforme."""
    
    def __init__(self, config_dir: str = "./config"):
        # Composants principaux
        self.config_manager = ConfigurationManager(config_dir)
        self.service_discovery = ServiceDiscovery('local')
        self.load_balancer = LoadBalancer('round_robin')
        self.health_checker = HealthChecker()
        self.metrics_collector = MetricsCollector()
        
        # √âtat de l'orchestrateur
        self.is_running = False
        self.services = {}  # Services g√©r√©s
        self.deployment_configs = {}
        self.api_gateway = None
        
        # Syst√®me de t√¢ches asynchrones
        self.task_queue = asyncio.Queue()
        self.workers = []
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # API REST pour contr√¥le
        self.web_app = None
        self.web_server = None
        
        self._initialize_services()
        
    def _initialize_services(self):
        """Initialise les services par d√©faut."""
        # Configuration des services de base
        services_config = self.config_manager.get_configuration('services')
        global_config = self.config_manager.get_configuration('global')
        
        base_port = global_config.get('networking', {}).get('base_port', 8000)
        
        # D√©finition des services de la plateforme
        service_definitions = [
            (ServiceType.SIMULATION, "physical_simulation", "Moteur de simulation physique"),
            (ServiceType.REALTIME_SYNC, "realtime_sync", "Synchronisation temps r√©el"),
            (ServiceType.PREDICTIVE_AI, "predictive_models", "Mod√®les pr√©dictifs IA"),
            (ServiceType.VISUALIZATION_3D, "visualization_3d", "Visualisation 3D"),
            (ServiceType.OPTIMIZATION, "autonomous_optimization", "Optimisation autonome"),
            (ServiceType.SECURITY, "security_framework", "Framework s√©curit√©"),
            (ServiceType.VR_AR_TRAINING, "vr_ar_training", "Formation VR/AR"),
        ]
        
        for i, (service_type, config_key, name) in enumerate(service_definitions):
            service_config = services_config.get(config_key, {})
            port = service_config.get('port', base_port + i + 1)
            
            service = ServiceInstance(
                service_id=f"{service_type.value}_001",
                service_type=service_type,
                name=name,
                version="1.0.0",
                host="localhost",
                port=port,
                config=service_config,
                health_check_url=f"http://localhost:{port}/health"
            )
            
            self.services[service.service_id] = service
            
            # Enregistrement dans le service discovery
            self.service_discovery.register_service(service)
            
            # Ajout au load balancer
            self.load_balancer.add_service_to_pool(service_type, service)
            
            # Enregistrement pour health check
            self.health_checker.register_service_for_health_check(service)
        
        logger.info(f"Initialis√© {len(self.services)} services")
    
    async def start_orchestrator(self):
        """D√©marre l'orchestrateur global."""
        if self.is_running:
            logger.warning("Orchestrateur d√©j√† en cours d'ex√©cution")
            return
        
        logger.info("üöÄ D√©marrage de l'orchestrateur global")
        self.is_running = True
        
        # D√©marrage des sous-syst√®mes
        asyncio.create_task(self.health_checker.start_health_monitoring())
        asyncio.create_task(self.metrics_collector.start_metrics_collection())
        asyncio.create_task(self._task_processor())
        asyncio.create_task(self._periodic_maintenance())
        
        # D√©marrage de l'API REST
        await self._start_api_server()
        
        logger.info("‚úÖ Orchestrateur global d√©marr√© avec succ√®s")
    
    async def _task_processor(self):
        """Traite les t√¢ches en arri√®re-plan."""
        while self.is_running:
            try:
                task = await asyncio.wait_for(self.task_queue.get(), timeout=1.0)
                await self._process_task(task)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Erreur traitement t√¢che: {e}")
    
    async def _process_task(self, task: Dict[str, Any]):
        """Traite une t√¢che sp√©cifique."""
        task_type = task.get('type')
        
        if task_type == 'deploy_service':
            await self._deploy_service(task['service_config'])
        elif task_type == 'scale_service':
            await self._scale_service(task['service_id'], task['replicas'])
        elif task_type == 'restart_service':
            await self._restart_service(task['service_id'])
        elif task_type == 'update_config':
            await self._update_service_config(task['service_id'], task['config'])
        else:
            logger.warning(f"Type de t√¢che inconnu: {task_type}")
    
    async def _periodic_maintenance(self):
        """Maintenance p√©riodique du syst√®me."""
        while self.is_running:
            try:
                await self._cleanup_old_metrics()
                await self._check_resource_usage()
                await self._auto_scale_services()
                await asyncio.sleep(300)  # Toutes les 5 minutes
            except Exception as e:
                logger.error(f"Erreur maintenance p√©riodique: {e}")
    
    async def _cleanup_old_metrics(self):
        """Nettoie les anciennes m√©triques."""
        cutoff_time = datetime.now() - timedelta(hours=24)
        
        # Nettoyage des m√©triques syst√®me
        self.metrics_collector.metrics_history = deque([
            m for m in self.metrics_collector.metrics_history
            if m.timestamp > cutoff_time
        ], maxlen=10000)
        
        # Nettoyage des m√©triques de services
        for service_id in self.metrics_collector.service_metrics:
            self.metrics_collector.service_metrics[service_id] = deque([
                m for m in self.metrics_collector.service_metrics[service_id]
                if m['timestamp'] > cutoff_time
            ], maxlen=1000)
    
    async def _check_resource_usage(self):
        """V√©rifie l'utilisation des ressources."""
        try:
            cpu_percent = psutil.cpu_percent()
            memory_percent = psutil.virtual_memory().percent
            
            # Alertes de ressources
            if cpu_percent > 90:
                logger.warning(f"Utilisation CPU √©lev√©e: {cpu_percent}%")
                await self._handle_high_resource_usage('cpu', cpu_percent)
            
            if memory_percent > 85:
                logger.warning(f"Utilisation m√©moire √©lev√©e: {memory_percent}%")
                await self._handle_high_resource_usage('memory', memory_percent)
                
        except Exception as e:
            logger.error(f"Erreur v√©rification ressources: {e}")
    
    async def _handle_high_resource_usage(self, resource_type: str, usage: float):
        """G√®re l'utilisation √©lev√©e des ressources."""
        # Strat√©gies de mitigation
        if resource_type == 'cpu' and usage > 95:
            # R√©duction temporaire de la charge
            await self._reduce_service_load()
        elif resource_type == 'memory' and usage > 90:
            # Red√©marrage des services gourmands
            await self._restart_memory_intensive_services()
    
    async def _auto_scale_services(self):
        """Auto-scaling des services selon la charge."""
        global_config = self.config_manager.get_configuration('global')
        if not global_config.get('scaling', {}).get('auto_scaling_enabled', False):
            return
        
        for service_id, service in self.services.items():
            if service.state == ServiceState.RUNNING:
                await self._evaluate_service_scaling(service)
    
    async def _evaluate_service_scaling(self, service: ServiceInstance):
        """√âvalue si un service doit √™tre mis √† l'√©chelle."""
        # M√©triques simplifi√©es pour la d√©mo
        cpu_threshold = 70
        target_replicas = 1
        
        if service.cpu_usage > cpu_threshold:
            target_replicas = min(3, target_replicas + 1)
            logger.info(f"Scaling up service {service.service_id}: CPU {service.cpu_usage}%")
        elif service.cpu_usage < cpu_threshold * 0.5:
            target_replicas = max(1, target_replicas - 1)
            logger.info(f"Scaling down service {service.service_id}: CPU {service.cpu_usage}%")
        
        # Application du scaling (simul√©)
        service.metadata['replicas'] = target_replicas
    
    async def deploy_service(self, service_type: ServiceType, 
                           deployment_config: DeploymentConfiguration) -> str:
        """D√©ploie un nouveau service."""
        service_id = f"{service_type.value}_{uuid.uuid4().hex[:8]}"
        
        # Cr√©ation de l'instance de service
        service = ServiceInstance(
            service_id=service_id,
            service_type=service_type,
            name=deployment_config.image.split(':')[0],
            version=deployment_config.image.split(':')[-1] if ':' in deployment_config.image else 'latest',
            host='localhost',
            port=8000 + len(self.services) + 1,  # Port dynamique
            config=deployment_config.environment_variables,
            state=ServiceState.STARTING
        )
        
        # Ajout au registre
        self.services[service_id] = service
        
        # T√¢che de d√©ploiement asynchrone
        await self.task_queue.put({
            'type': 'deploy_service',
            'service_config': {
                'service': service,
                'deployment_config': deployment_config
            }
        })
        
        logger.info(f"D√©ploiement demand√© pour {service_id}")
        return service_id
    
    async def _deploy_service(self, service_config: Dict[str, Any]):
        """D√©ploie effectivement un service."""
        service = service_config['service']
        deployment_config = service_config['deployment_config']
        
        try:
            logger.info(f"D√©ploiement de {service.service_id}")
            
            # Simulation du d√©ploiement
            await asyncio.sleep(2)  # Simulation du temps de d√©ploiement
            
            # Mise √† jour de l'√©tat
            service.state = ServiceState.RUNNING
            service.start_time = datetime.now()
            service.health_status = HealthStatus.HEALTHY
            
            # Enregistrement dans le service discovery
            self.service_discovery.register_service(service)
            
            # Ajout au load balancer
            self.load_balancer.add_service_to_pool(service.service_type, service)
            
            # Enregistrement pour health check
            self.health_checker.register_service_for_health_check(service)
            
            logger.info(f"Service {service.service_id} d√©ploy√© avec succ√®s")
            
        except Exception as e:
            service.state = ServiceState.ERROR
            logger.error(f"Erreur d√©ploiement {service.service_id}: {e}")
    
    async def stop_service(self, service_id: str) -> bool:
        """Arr√™te un service."""
        if service_id not in self.services:
            return False
        
        service = self.services[service_id]
        
        try:
            logger.info(f"Arr√™t du service {service_id}")
            
            # Mise √† jour de l'√©tat
            service.state = ServiceState.STOPPING
            
            # Retrait du load balancer
            self.load_balancer.remove_service_from_pool(service.service_type, service_id)
            
            # D√©senregistrement du service discovery
            self.service_discovery.deregister_service(service_id, service.service_type)
            
            # Simulation de l'arr√™t
            await asyncio.sleep(1)
            
            service.state = ServiceState.STOPPED
            logger.info(f"Service {service_id} arr√™t√©")
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur arr√™t service {service_id}: {e}")
            service.state = ServiceState.ERROR
            return False
    
    async def restart_service(self, service_id: str) -> bool:
        """Red√©marre un service."""
        if service_id not in self.services:
            return False
        
        service = self.services[service_id]
        original_state = service.state
        
        try:
            # Arr√™t
            await self.stop_service(service_id)
            
            # Attente
            await asyncio.sleep(2)
            
            # Red√©marrage
            service.state = ServiceState.STARTING
            service.restart_count += 1
            
            await asyncio.sleep(3)  # Simulation red√©marrage
            
            service.state = ServiceState.RUNNING
            service.start_time = datetime.now()
            service.health_status = HealthStatus.HEALTHY
            
            # R√©enregistrement
            self.service_discovery.register_service(service)
            self.load_balancer.add_service_to_pool(service.service_type, service)
            
            logger.info(f"Service {service_id} red√©marr√© (tentative #{service.restart_count})")
            return True
            
        except Exception as e:
            logger.error(f"Erreur red√©marrage service {service_id}: {e}")
            service.state = ServiceState.ERROR
            return False
    
    async def _start_api_server(self):
        """D√©marre le serveur API REST."""
        from aiohttp import web, web_runner
        
        app = web.Application()
        
        # Routes API
        app.router.add_get('/health', self._api_health_check)
        app.router.add_get('/services', self._api_list_services)
        app.router.add_get('/services/{service_id}', self._api_get_service)
        app.router.add_post('/services/{service_id}/restart', self._api_restart_service)
        app.router.add_delete('/services/{service_id}', self._api_stop_service)
        app.router.add_get('/metrics', self._api_get_metrics)
        app.router.add_get('/status', self._api_system_status)
        
        # D√©marrage du serveur
        runner = web_runner.AppRunner(app)
        await runner.setup()
        
        site = web_runner.TCPSite(runner, 'localhost', 9000)
        await site.start()
        
        self.web_server = runner
        logger.info("API REST d√©marr√©e sur http://localhost:9000")
    
    async def _api_health_check(self, request):
        """Endpoint de health check."""
        from aiohttp import web
        
        return web.json_response({
            'status': 'healthy' if self.is_running else 'unhealthy',
            'timestamp': datetime.now().isoformat(),
            'version': '1.0.0'
        })
    
    async def _api_list_services(self, request):
        """Liste tous les services."""
        from aiohttp import web
        
        services_data = []
        for service in self.services.values():
            services_data.append({
                'service_id': service.service_id,
                'service_type': service.service_type.value,
                'name': service.name,
                'state': service.state.value,
                'health_status': service.health_status.value,
                'host': service.host,
                'port': service.port,
                'start_time': service.start_time.isoformat() if service.start_time else None,
                'restart_count': service.restart_count
            })
        
        return web.json_response({
            'services': services_data,
            'total_count': len(services_data)
        })
    
    async def _api_get_service(self, request):
        """R√©cup√®re les d√©tails d'un service."""
        from aiohttp import web
        
        service_id = request.match_info['service_id']
        
        if service_id not in self.services:
            return web.json_response({'error': 'Service not found'}, status=404)
        
        service = self.services[service_id]
        
        return web.json_response({
            'service_id': service.service_id,
            'service_type': service.service_type.value,
            'name': service.name,
            'version': service.version,
            'state': service.state.value,
            'health_status': service.health_status.value,
            'host': service.host,
            'port': service.port,
            'start_time': service.start_time.isoformat() if service.start_time else None,
            'restart_count': service.restart_count,
            'cpu_usage': service.cpu_usage,
            'memory_usage': service.memory_usage,
            'last_health_check': service.last_health_check.isoformat() if service.last_health_check else None,
            'dependencies': service.dependencies,
            'config': service.config,
            'metadata': service.metadata
        })
    
    async def _api_restart_service(self, request):
        """Red√©marre un service."""
        from aiohttp import web
        
        service_id = request.match_info['service_id']
        
        if service_id not in self.services:
            return web.json_response({'error': 'Service not found'}, status=404)
        
        success = await self.restart_service(service_id)
        
        if success:
            return web.json_response({'message': f'Service {service_id} restart initiated'})
        else:
            return web.json_response({'error': 'Failed to restart service'}, status=500)
    
    async def _api_stop_service(self, request):
        """Arr√™te un service."""
        from aiohttp import web
        
        service_id = request.match_info['service_id']
        
        if service_id not in self.services:
            return web.json_response({'error': 'Service not found'}, status=404)
        
        success = await self.stop_service(service_id)
        
        if success:
            return web.json_response({'message': f'Service {service_id} stopped'})
        else:
            return web.json_response({'error': 'Failed to stop service'}, status=500)
    
    async def _api_get_metrics(self, request):
        """R√©cup√®re les m√©triques syst√®me."""
        from aiohttp import web
        
        metrics_summary = self.metrics_collector.get_system_metrics_summary(timedelta(hours=1))
        
        # Ajout des m√©triques de services
        service_metrics = {}
        for service_id, service in self.services.items():
            service_metrics[service_id] = {
                'cpu_usage': service.cpu_usage,
                'memory_usage': service.memory_usage,
                'restart_count': service.restart_count,
                'health_status': service.health_status.value,
                'uptime_seconds': (datetime.now() - service.start_time).total_seconds() if service.start_time else 0
            }
        
        return web.json_response({
            'system_metrics': metrics_summary,
            'service_metrics': service_metrics,
            'timestamp': datetime.now().isoformat()
        })
    
    async def _api_system_status(self, request):
        """Statut global du syst√®me."""
        from aiohttp import web
        
        running_services = sum(1 for s in self.services.values() if s.state == ServiceState.RUNNING)
        healthy_services = sum(1 for s in self.services.values() if s.health_status == HealthStatus.HEALTHY)
        
        return web.json_response({
            'orchestrator_status': 'running' if self.is_running else 'stopped',
            'total_services': len(self.services),
            'running_services': running_services,
            'healthy_services': healthy_services,
            'system_uptime': time.time() - psutil.boot_time(),
            'platform_version': '1.0.0',
            'components': {
                'service_discovery': 'active',
                'load_balancer': 'active',
                'health_checker': 'active' if self.health_checker.is_running else 'inactive',
                'metrics_collector': 'active' if self.metrics_collector.is_collecting else 'inactive'
            }
        })
    
    async def stop_orchestrator(self):
        """Arr√™te l'orchestrateur global."""
        if not self.is_running:
            return
        
        logger.info("üõë Arr√™t de l'orchestrateur global")
        self.is_running = False
        
        # Arr√™t des sous-syst√®mes
        self.health_checker.stop_health_monitoring()
        self.metrics_collector.stop_metrics_collection()
        
        # Arr√™t de tous les services
        for service_id in list(self.services.keys()):
            await self.stop_service(service_id)
        
        # Arr√™t du serveur API
        if self.web_server:
            await self.web_server.cleanup()
        
        # Nettoyage des ressources
        self.config_manager.cleanup()
        self.executor.shutdown(wait=True)
        
        logger.info("‚úÖ Orchestrateur global arr√™t√©")
    
    def get_system_dashboard(self) -> Dict[str, Any]:
        """Tableau de bord syst√®me complet."""
        # √âtats des services
        service_states = defaultdict(int)
        service_health = defaultdict(int)
        
        for service in self.services.values():
            service_states[service.state.value] += 1
            service_health[service.health_status.value] += 1
        
        # M√©triques syst√®me r√©centes
        recent_metrics = self.metrics_collector.get_system_metrics_summary(timedelta(hours=1))
        
        # Informations syst√®me
        system_info = {
            'hostname': platform.node(),
            'platform': platform.system(),
            'architecture': platform.architecture()[0],
            'python_version': platform.python_version(),
            'uptime_seconds': time.time() - psutil.boot_time()
        }
        
        return {
            'timestamp': datetime.now().isoformat(),
            'orchestrator_status': 'running' if self.is_running else 'stopped',
            'system_info': system_info,
            'service_overview': {
                'total_services': len(self.services),
                'states': dict(service_states),
                'health_status': dict(service_health)
            },
            'system_metrics': recent_metrics,
            'component_status': {
                'configuration_manager': 'active',
                'service_discovery': 'active',
                'load_balancer': 'active',
                'health_checker': 'active' if self.health_checker.is_running else 'inactive',
                'metrics_collector': 'active' if self.metrics_collector.is_collecting else 'inactive',
                'api_server': 'active' if self.web_server else 'inactive'
            }
        }

# Fonction de d√©monstration
async def main():
    """D√©monstration du syst√®me d'orchestration global."""
    
    print("=== Syst√®me d'Orchestration et d'Int√©gration Globale ===")
    print("üéØ Station Traffey√®re IoT AI Platform - Orchestrateur Central")
    print()
    
    # Initialisation de l'orchestrateur
    orchestrator = GlobalOrchestrator()
    
    print("‚úÖ Orchestrateur global initialis√©")
    print()
    
    try:
        # D√©marrage de l'orchestrateur
        print("üöÄ D√©marrage de l'orchestrateur...")
        await orchestrator.start_orchestrator()
        
        print("‚úÖ Orchestrateur d√©marr√© avec succ√®s")
        print()
        
        # Attente pour la stabilisation
        await asyncio.sleep(3)
        
        # Affichage du tableau de bord
        print("üìä Tableau de bord du syst√®me:")
        print("=" * 60)
        
        dashboard = orchestrator.get_system_dashboard()
        
        print(f"üñ•Ô∏è  Syst√®me: {dashboard['system_info']['hostname']} ({dashboard['system_info']['platform']})")
        print(f"‚ö° Statut orchestrateur: {dashboard['orchestrator_status'].upper()}")
        print()
        
        # Vue d'ensemble des services
        service_overview = dashboard['service_overview']
        print(f"üì± Services total: {service_overview['total_services']}")
        
        for state, count in service_overview['states'].items():
            emoji = {'running': 'üü¢', 'stopped': 'üî¥', 'starting': 'üü°', 'error': '‚ùå'}.get(state, '‚ö™')
            print(f"  {emoji} {state.capitalize()}: {count}")
        
        print()
        print("üè• √âtat de sant√© des services:")
        for status, count in service_overview['health_status'].items():
            emoji = {'healthy': 'üíö', 'unhealthy': 'üíî', 'degraded': 'üíõ', 'unknown': 'üí≠'}.get(status, '‚ö™')
            print(f"  {emoji} {status.capitalize()}: {count}")
        
        print()
        
        # M√©triques syst√®me
        if dashboard.get('system_metrics') and dashboard['system_metrics']:
            metrics = dashboard['system_metrics']
            if 'cpu_usage' in metrics:
                print("üìä M√©triques syst√®me (1h):")
                print(f"  üíª CPU moyen: {metrics['cpu_usage']['avg']:.1f}%")
                print(f"  üß† M√©moire moyenne: {metrics['memory_usage']['avg']:.1f}%")
                print(f"  üìà √âchantillons: {metrics.get('time_range', {}).get('samples', 0)}")
                print()
        
        # √âtat des composants
        print("üîß √âtat des composants:")
        components = dashboard['component_status']
        for component, status in components.items():
            emoji = '‚úÖ' if status == 'active' else '‚ùå'
            name = component.replace('_', ' ').title()
            print(f"  {emoji} {name}: {status}")
        
        print()
        
        # Test des fonctionnalit√©s de l'orchestrateur
        print("üß™ Test des fonctionnalit√©s d'orchestration...")
        print()
        
        # 1. Test de red√©marrage de service
        print("üîÑ Test de red√©marrage d'un service...")
        service_id = list(orchestrator.services.keys())[0]
        success = await orchestrator.restart_service(service_id)
        
        if success:
            print(f"  ‚úÖ Service {service_id} red√©marr√© avec succ√®s")
        else:
            print(f"  ‚ùå √âchec du red√©marrage du service {service_id}")
        
        # Attente pour voir l'effet
        await asyncio.sleep(2)
        
        # 2. V√©rification de l'√©tat apr√®s red√©marrage
        service = orchestrator.services[service_id]
        print(f"  üìä √âtat: {service.state.value}, Sant√©: {service.health_status.value}")
        print(f"  üîÑ Nombre de red√©marrages: {service.restart_count}")
        
        print()
        
        # 3. Test de d√©ploiement d'un nouveau service
        print("üöÄ Test de d√©ploiement d'un nouveau service...")
        
        deployment_config = DeploymentConfiguration(
            service_type=ServiceType.API_GATEWAY,
            image="nginx:latest",
            replicas=1,
            resource_requests={'cpu': '100m', 'memory': '128Mi'},
            resource_limits={'cpu': '500m', 'memory': '512Mi'},
            environment_variables={'ENV': 'production', 'LOG_LEVEL': 'info'}
        )
        
        new_service_id = await orchestrator.deploy_service(ServiceType.API_GATEWAY, deployment_config)
        print(f"  üì¶ Nouveau service d√©ploy√©: {new_service_id}")
        
        # Attente du d√©ploiement
        await asyncio.sleep(3)
        
        # V√©rification du d√©ploiement
        if new_service_id in orchestrator.services:
            new_service = orchestrator.services[new_service_id]
            print(f"  ‚úÖ D√©ploiement r√©ussi - √âtat: {new_service.state.value}")
        else:
            print(f"  ‚ùå √âchec du d√©ploiement")
        
        print()
        
        # 4. Affichage des m√©triques finales
        print("üìà M√©triques finales du syst√®me:")
        final_dashboard = orchestrator.get_system_dashboard()
        final_overview = final_dashboard['service_overview']
        
        print(f"  üì± Services total: {final_overview['total_services']}")
        print(f"  üü¢ Services actifs: {final_overview['states'].get('running', 0)}")
        print(f"  üíö Services sains: {final_overview['health_status'].get('healthy', 0)}")
        
        print()
        
        # 5. Test de l'API REST
        print("üåê Test de l'API REST...")
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get('http://localhost:9000/health') as resp:
                    if resp.status == 200:
                        health_data = await resp.json()
                        print(f"  ‚úÖ API REST accessible - Statut: {health_data['status']}")
                    else:
                        print(f"  ‚ùå Erreur API - Code: {resp.status}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  API non testable: {e}")
        
        print()
        
        # Informations sur l'acc√®s API
        print("üåê Acc√®s √† l'API REST:")
        print("  Base URL: http://localhost:9000")
        print("  Endpoints disponibles:")
        print("    GET  /health          - Health check de l'orchestrateur")
        print("    GET  /services        - Liste des services")
        print("    GET  /services/{id}   - D√©tails d'un service")
        print("    POST /services/{id}/restart - Red√©marrer un service")
        print("    DELETE /services/{id} - Arr√™ter un service")
        print("    GET  /metrics         - M√©triques syst√®me")
        print("    GET  /status          - Statut global")
        
        print()
        print("üéâ D√©monstration de l'orchestrateur termin√©e avec succ√®s !")
        print()
        print("‚öôÔ∏è Fonctionnalit√©s d√©montr√©es:")
        print("  ‚úì Orchestration centralis√©e de tous les composants")
        print("  ‚úì Service discovery et registre des services")
        print("  ‚úì Load balancing intelligent entre instances")
        print("  ‚úì Health checking automatique et continu")
        print("  ‚úì Collecte de m√©triques syst√®me et applicatives")
        print("  ‚úì D√©ploiement et scaling automatique")
        print("  ‚úì API REST pour contr√¥le et monitoring")
        print("  ‚úì Configuration centralis√©e avec hot-reload")
        print("  ‚úì Auto-recovery et maintenance automatique")
        
        # Maintien de l'orchestrateur actif
        print()
        print("üîÑ Orchestrateur maintenu actif pour 30 secondes...")
        print("   (Utilisez Ctrl+C pour arr√™ter)")
        
        try:
            await asyncio.sleep(30)
        except KeyboardInterrupt:
            print("\n‚ö° Interruption d√©tect√©e")
        
    except Exception as e:
        print(f"‚ùå Erreur durant la d√©monstration: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Arr√™t propre de l'orchestrateur
        print("\nüõë Arr√™t de l'orchestrateur...")
        await orchestrator.stop_orchestrator()
        print("‚úÖ Orchestrateur arr√™t√© proprement")

if __name__ == "__main__":
    # Gestion des signaux pour arr√™t propre
    def signal_handler(signum, frame):
        print("\nüõë Signal d'arr√™t re√ßu")
        raise KeyboardInterrupt()
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    asyncio.run(main())